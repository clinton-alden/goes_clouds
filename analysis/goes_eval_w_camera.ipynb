{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using manually classified timelapse camera data to find GOES multi-spectral thresholds\n",
    "\n",
    "We want to find a combination of thresholds from the GOES Day Cloud Phase RGB bands that will help predict cloud/no cloud for all pixels over Western Washington. We have manually identified cloud types for daylight hours between 13 July 2022 and 30 September 2022 for Friday Harbor and Cattle Point.\n",
    "\n",
    "#### Methods:\n",
    "1. Create RGB composite files for all the desired dates\n",
    "2. Match RGB composites for the pixel just East of cameras for corresponding timesteps\n",
    "    - GOES data is 5min but cameras are 30min\n",
    "    - one pixel East because cameras look East towards Lopez and Shaw islands ~1-2km away\n",
    "3. Only look at times with blue sky only or 2 or fewer cloud types \n",
    "    - gets way too messy when there is patchy cloud cover/many types of clouds\n",
    "4. Get rid of timesteps and combine both sites cloud data with their corresponding GOES pixels\n",
    "5. Use a decision tree to find the thresholds\n",
    "\n",
    "#### Next Steps:\n",
    "1. Redownload GOES data for the same dates but a larger spatial domain\n",
    "    - see manuscript for domain bounds\n",
    "2. Create a cloud/no cloud frequency map\n",
    "3. Compare to GOES cloud mask that only uses thermal\n",
    "    - theoretically, this will be very different specifically over the ocean\n",
    "    - GOES cloud mask confuses cold water with low clouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data = pd.read_csv('CP2022photos.csv', index_col=0, parse_dates=True)\n",
    "camera_data.index = camera_data.index.tz_localize('America/Los_Angeles')\n",
    "camera_data.index = camera_data.index.round('5min')\n",
    "camera_data = camera_data.loc['2022-07-13':'2022-08-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_data_july = {}\n",
    "goes_df_july = {}\n",
    "for i in range(13, 32):\n",
    "    key = f\"goes_data_july{i}\"  # Dynamically generate the key\n",
    "    filename = f\"/storage/cdalden/goes/washington/goes17/rgb_composite/goes17_C02_C05_C13_rgb_washington_202207{i}.nc\"  # Dynamically generate the filename\n",
    "    goes_data_july[key] = xr.open_dataset(filename)\n",
    "\n",
    "    # select data near 48.5N and -123.5W\n",
    "    lat = 48.464462\n",
    "    lon = -122.9 # offset by ~0.05deg (1 grid cell) to east since that is where camera looks\n",
    "    # Select data and convert to dataframe\n",
    "    df_key = f\"goes_df_july{i}\"\n",
    "    goes_df_july[df_key] = (\n",
    "        goes_data_july[key]\n",
    "        .sel(latitude=lat, longitude=lon, method='nearest')\n",
    "        .drop_vars(['latitude', 'longitude'])\n",
    "        .to_dataframe()\n",
    "    )\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "goes_df_july_all = pd.concat(goes_df_july.values(), axis=0)\n",
    "\n",
    "# Convert goes times to PDT\n",
    "goes_df_july_all.index = goes_df_july_all.index.tz_localize('UTC').tz_convert('America/Los_Angeles')\n",
    "goes_df_july_all.index = goes_df_july_all.index.round('5min')\n",
    "\n",
    "# Subset by time range (0600 to 2000 hours)\n",
    "goes_df_july_all = goes_df_july_all.between_time('06:00', '19:30')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_data_aug = {}\n",
    "goes_df_aug = {}\n",
    "for i in range(1, 8):\n",
    "    key = f\"goes_data_aug{i}\"  # Dynamically generate the key\n",
    "    filename = f\"/storage/cdalden/goes/washington/goes17/rgb_composite/goes17_C02_C05_C13_rgb_washington_2022080{i}.nc\"  # Dynamically generate the filename\n",
    "    goes_data_aug[key] = xr.open_dataset(filename)\n",
    "\n",
    "    # select data near 48.5N and -123.5W\n",
    "    lat = 48.464462\n",
    "    lon = -122.9 # offset by ~0.05deg (1 grid cell) to east since that is where camera looks\n",
    "    # Select data and convert to dataframe\n",
    "    df_key = f\"goes_df_aug{i}\"\n",
    "    goes_df_aug[df_key] = (\n",
    "        goes_data_aug[key]\n",
    "        .sel(latitude=lat, longitude=lon, method='nearest')\n",
    "        .drop_vars(['latitude', 'longitude'])\n",
    "        .to_dataframe()\n",
    "    )\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "goes_df_aug_all = pd.concat(goes_df_aug.values(), axis=0)\n",
    "\n",
    "# Convert goes times to PDT\n",
    "goes_df_aug_all.index = goes_df_aug_all.index.tz_localize('UTC').tz_convert('America/Los_Angeles')\n",
    "goes_df_aug_all.index = goes_df_aug_all.index.round('5min')\n",
    "\n",
    "# Subset by time range (0600 to 2000 hours)\n",
    "goes_df_aug_all = goes_df_aug_all.between_time('06:00', '19:30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_data_sep = {}\n",
    "goes_df_sep = {}\n",
    "for i in range(1, 10):\n",
    "    key = f\"goes_data_sep{i}\"  # Dynamically generate the key\n",
    "    filename = f\"/storage/cdalden/goes/washington/goes17/rgb_composite/goes17_C02_C05_C13_rgb_washington_2022090{i}.nc\"  # Dynamically generate the filename\n",
    "    goes_data_sep[key] = xr.open_dataset(filename)\n",
    "\n",
    "    # select data near 48.5N and -123.5W\n",
    "    lat = 48.464462\n",
    "    lon = -122.85 # offset by ~0.1deg (2 grid cells, ) to east since that is where camera looks\n",
    "    # Select data and convert to dataframe\n",
    "    df_key = f\"goes_df_sep{i}\"\n",
    "    goes_df_sep[df_key] = (\n",
    "        goes_data_sep[key]\n",
    "        .sel(latitude=lat, longitude=lon, method='nearest')\n",
    "        .drop_vars(['latitude', 'longitude'])\n",
    "        .to_dataframe()\n",
    "    )\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "goes_df_sep_all = pd.concat(goes_df_sep.values(), axis=0)\n",
    "\n",
    "# Convert goes times to PDT\n",
    "goes_df_sep_all.index = goes_df_sep_all.index.tz_localize('UTC').tz_convert('America/Los_Angeles')\n",
    "goes_df_sep_all.index = goes_df_sep_all.index.round('5min')\n",
    "\n",
    "# Subset by time range (0600 to 2000 hours)\n",
    "goes_df_sep_all = goes_df_sep_all.between_time('06:00', '19:30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clouds\n",
      "b     601\n",
      "s     206\n",
      "f      43\n",
      "sc     24\n",
      "r      10\n",
      "cr      8\n",
      "c       2\n",
      "fs      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine July and August data\n",
    "goes_df_summer_all = pd.concat([goes_df_july_all, goes_df_aug_all, goes_df_sep_all])\n",
    "# Ensure the time indices align\n",
    "data = goes_df_summer_all.join(camera_data, how='inner')\n",
    "data = data.dropna()\n",
    "\n",
    "# Drop timesteps with more than 2 cloud types\n",
    "data = data[data['clouds'].str.len() <= 2]\n",
    "\n",
    "# Drop times when bluesky and string is 2 characters long (i.e., bluesky + 1 cloud type)\n",
    "data = data[~((data['clouds'].str.len() == 2) & (data['clouds'].str.contains('b')))]\n",
    "\n",
    "print(data['clouds'].value_counts(\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by time and clouds to count occurrences\n",
    "cloud_counts = data.groupby([data.index, 'clouds']).size().unstack(fill_value=0)\n",
    "\n",
    "# Normalize counts to get proportions\n",
    "cloud_proportions = cloud_counts.div(cloud_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# # Plot the stacked area chart\n",
    "# cloud_proportions.plot(kind='area', stacked=True, alpha=0.7, figsize=(10, 6))\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Proportion')\n",
    "# plt.title('Cloud Categories Proportion Over Time')\n",
    "# plt.legend(title='Clouds')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rules:\n",
      " |--- green <= 0.13\n",
      "|   |--- red <= 0.00\n",
      "|   |   |--- blue <= 0.26\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- blue >  0.26\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- red >  0.00\n",
      "|   |   |--- blue <= 0.03\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- blue >  0.03\n",
      "|   |   |   |--- class: 0\n",
      "|--- green >  0.13\n",
      "|   |--- green <= 0.13\n",
      "|   |   |--- class: 0\n",
      "|   |--- green >  0.13\n",
      "|   |   |--- class: 0\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.92        64\n",
      "           1       0.92      1.00      0.96       116\n",
      "\n",
      "    accuracy                           0.94       180\n",
      "   macro avg       0.96      0.92      0.94       180\n",
      "weighted avg       0.95      0.94      0.94       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Create binary target variable: 1 if 'clouds' contains 'b' (no clouds), 0 otherwise (clouds)\n",
    "data['no_clouds'] = data['clouds'].str.contains('b').astype(int)\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = data[['red', 'green', 'blue']]  # Replace with your variable names\n",
    "y = data['no_clouds']  # Binary target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, min_samples_split=10, class_weight='balanced', random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the decision tree rules\n",
    "tree_rules = export_text(tree_model, feature_names=['red', 'green', 'blue'])\n",
    "print(\"Decision Tree Rules:\\n\", tree_rules)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "F1 Score: 0.961038961038961\n",
      "Precision: 0.9652173913043478\n",
      "Recall: 0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score based on thresholds: 0.6878306878306878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define a function to classify based on the thresholds\n",
    "def classify_based_on_thresholds(row):\n",
    "    if row['green'] <= 0.13:\n",
    "        if row['red'] <= 0.00:\n",
    "            if row['blue'] <= 0.26:\n",
    "                return 1  # Class 1 (no clouds)\n",
    "    return 0  # Class 0 (clouds)\n",
    "\n",
    "# Apply the function to the test set\n",
    "manual_predictions = X_test.apply(classify_based_on_thresholds, axis=1)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test, manual_predictions)\n",
    "print(\"F1 Score based on thresholds:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
